{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(df1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df2=df1[['Net.Due.Dt','Clearing','Status']]\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['Range of Delay']=pd.to_datetime(df2['Clearing'],yearfirst=True)-pd.to_datetime(df2['Net.Due.Dt'],yearfirst=True)\n",
    "    df2['Range of Delay']=df2['Range of Delay'].dt.days\n",
    "    df2['Range of Delay']=pd.to_numeric(df2['Range of Delay'])\n",
    "    df2 = df2.reset_index()\n",
    "    df2.drop(columns='index',inplace=True)\n",
    "    df2['Status'] = np.where(df2['Range of Delay'] > 180, 8, \n",
    "         (np.where(df2['Range of Delay'] > 90, 7,(np.where(df2['Range of Delay'] > 60, 6, (np.where(df2['Range of Delay'] > 30, 5, (np.where(df2['Range of Delay'] > 15, 4, (np.where(df2['Range of Delay'] > 7, 3, (np.where(df2['Range of Delay'] > 3, 2, (np.where(df2['Range of Delay'] > 0, 1 ,0)))))))))))))))\n",
    "    df1['Status']=df2['Status']\n",
    "    df1.dropna(inplace=True)\n",
    "    df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=df1['BusA'].astype('category').cat.codes\n",
    "    df1['CCAr']=df1['CCAr'].astype('category').cat.codes\n",
    "    #df['Account']=df['Account'].astype('category').cat.codes\n",
    "    #df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Month','Year','Clrng.doc.'],inplace=True)\n",
    "    df1['Zone']=df1['Zone'].astype('category').cat.codes\n",
    "    df1['Bran']=df1['Bran'].astype('category').cat.codes\n",
    "    df1['PayT'] = df1['PayT'].astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1.drop(columns=['Net.Due.Dt','Clearing'],inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(df1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import preprocessing\n",
    "    y=np.array(df1['Status'])\n",
    "    df1.drop(columns='Status',inplace=True)\n",
    "    \n",
    "    y1=df1.columns\n",
    "    x = df1.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    X=df1\n",
    "    #df1.head(5)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3)\n",
    "    # Random forest Model: \n",
    "    model= RandomForestClassifier(n_estimators = 100, criterion='entropy',random_state = 0)\n",
    "    # Decion Tree Model: \n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=100)\n",
    "    # AdaBoost Classifier Model:\n",
    "    clf = AdaBoostClassifier(base_estimator=decision_tree,n_estimators=100, random_state=0)\n",
    "    # KNN :\n",
    "    mo = neighbors.KNeighborsClassifier(n_neighbors =2)\n",
    "    # Bagging Classifier Model:  \n",
    "    bagging = BaggingClassifier(mo,max_samples=0.5, max_features=0.5)\n",
    "    #Voting Classifier\n",
    "    eclf = VotingClassifier(estimators=[ ('knn', bagging), ('adaboost', clf), ('RF',model)],voting='soft', weights=[1,4,5])\n",
    "    eclf1 = eclf.fit(xtrain, ytrain)\n",
    "    eclf2=eclf.predict(xtest)\n",
    "    voteprob=eclf.predict_proba(xtest)\n",
    "    print('TRAINING REULTS-----------------------------------------')\n",
    "    print(\"Accuracy: for Voting :\",metrics.accuracy_score(ytest, eclf2)*100)\n",
    "    print()\n",
    "    print('Confusion Matrix for Voting')\n",
    "    print(metrics.confusion_matrix(eclf2, ytest))\n",
    "    print()\n",
    "    print('--------------------------------------------------------------------------------------------------------------------')\n",
    "    return eclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df,clf,df1):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    prediction=clf.predict(df)\n",
    "    predictprob=clf.predict_proba(df)\n",
    "    df1['Prediction']=np.zeros(len(df))\n",
    "    #df['Probability']=np.zeros(len(df))\n",
    "    arr=['No delay','0-3 days','4-7 days','8-15 days','16-30 days','31-60 days','61-90 days','90-180 days','>180 days']\n",
    "    for i in range(len(prediction)):\n",
    "        print('Customer Selected:',int(df['Account'][i]))\n",
    "        print()\n",
    "        print('------------------------------------------------------------------------------------------------------------')\n",
    "        print()\n",
    "        print(arr[prediction[i]],'<----- The predicted value , The probabilities :----->')\n",
    "        df1['Prediction'][i]=arr[prediction[i]]\n",
    "        #df['Probability'][i]=predictprob[i]\n",
    "        for j in range(len(predictprob[i])):\n",
    "            print('Probability of being ', arr[j],' is: ', predictprob[i][j])\n",
    "        print()\n",
    "        print('-----------------------------------------------------------------------------------------')\n",
    "        df1.to_csv('Predicted1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import time\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import copy\n",
    "    trainpath='MyData.csv'\n",
    "    df1=pd.read_csv(trainpath)\n",
    "    print(df1.head(5))\n",
    "    df3=copy.deepcopy(df1)\n",
    "    df2=preprocessor(df1)\n",
    "    print(df2.head(5))\n",
    "    clf=trainer(df2)\n",
    "    print('Training Done...................')\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    testpath=df2[:5]\n",
    "    predict(testpath,clf,df3[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BusA CCAr     Reference  Account          Customer.Name   Zone  Bran  Ty  \\\n",
      "0  1000  BPR  4.132000e+09   929488      KAUSALYA AGENCIES  South  SBAD  RV   \n",
      "1  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "2  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "3  9600  BPR  2.146119e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "4  2500  BPR  2.410320e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "\n",
      "    Status  Local.Crcy.Amt  ...  Doc.Chq.dt Month  Pstng.Date  Net.Due.Dt  \\\n",
      "0   Not OD            0.10  ...  31.12.2018   Dec  2018-12-31  2019-01-05   \n",
      "1  Overdue            0.04  ...  31.10.2018   Oct  2018-10-31  2018-11-10   \n",
      "2   Not OD            0.12  ...  05.11.2018   Nov  2018-11-05  2018-11-15   \n",
      "3  Overdue            0.14  ...  27.10.2018   Oct  2018-10-27  2018-11-06   \n",
      "4  Overdue            0.16  ...  03.11.2018   Nov  2018-11-03  2018-11-13   \n",
      "\n",
      "       G.L  Year Clrng.doc.    Clearing  Pending_Amy  pending_cnt  \n",
      "0  1221001  2019   94177601  2018-12-31         0.00            0  \n",
      "1  1221001  2019   93892774  2018-11-15         0.60            4  \n",
      "2  1221001  2019   93892774  2018-11-15         1.42           10  \n",
      "3  1221001  2019   93892773  2018-11-14         0.00            0  \n",
      "4  1221001  2019   93892774  2018-11-15         1.26            9  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "   BusA  CCAr     Reference  Account  Zone  Bran  Status  Local.Crcy.Amt  \\\n",
      "0     0     0  4.132000e+09   929488     2    21       0            0.10   \n",
      "1     6     0  1.115502e+09   928860     1     9       2            0.04   \n",
      "2     6     0  1.115502e+09   928860     1     9       0            0.12   \n",
      "3     6     0  2.146119e+09   928860     1     9       3            0.14   \n",
      "4     2     0  2.410320e+09   928860     1     9       1            0.16   \n",
      "\n",
      "   PayT Pstng.Date      G.L  Pending_Amy  pending_cnt  \n",
      "0    27   20181231  1221001         0.00            0  \n",
      "1    31   20181031  1221001         0.60            4  \n",
      "2    31   20181105  1221001         1.42           10  \n",
      "3    31   20181027  1221001         0.00            0  \n",
      "4    31   20181103  1221001         1.26            9  \n",
      "TRAINING REULTS-----------------------------------------\n",
      "Accuracy: for Voting : 92.99701002520959\n",
      "\n",
      "Confusion Matrix for Voting\n",
      "[[26504   963   202    77    36     0]\n",
      " [  447  3364   212    42    10     0]\n",
      " [   54   115  1159    96     6     0]\n",
      " [   16    20    58   582    20     0]\n",
      " [    4     1     3     7   114     0]\n",
      " [    0     0     0     0     0     2]]\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Training Done...................\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Customer Selected: 929488\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "No delay <----- The predicted value , The probabilities :----->\n",
      "Probability of being  No delay  is:  0.7045442503071382\n",
      "Probability of being  0-3 days  is:  0.09509853044231828\n",
      "Probability of being  4-7 days  is:  0.0503546884940725\n",
      "Probability of being  8-15 days  is:  0.055001605731434824\n",
      "Probability of being  16-30 days  is:  0.07000089395923001\n",
      "Probability of being  31-60 days  is:  0.025000031065806217\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Customer Selected: 928860\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "No delay <----- The predicted value , The probabilities :----->\n",
      "Probability of being  No delay  is:  0.5009746263194379\n",
      "Probability of being  0-3 days  is:  0.07598545730758828\n",
      "Probability of being  4-7 days  is:  0.19197488853303704\n",
      "Probability of being  8-15 days  is:  0.09433903760469028\n",
      "Probability of being  16-30 days  is:  0.13672598840785083\n",
      "Probability of being  31-60 days  is:  1.827395604464701e-09\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Customer Selected: 928860\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "No delay <----- The predicted value , The probabilities :----->\n",
      "Probability of being  No delay  is:  0.3570444666671337\n",
      "Probability of being  0-3 days  is:  0.2198147171367025\n",
      "Probability of being  4-7 days  is:  0.2053130720668311\n",
      "Probability of being  8-15 days  is:  0.09108481298345307\n",
      "Probability of being  16-30 days  is:  0.1267429269292904\n",
      "Probability of being  31-60 days  is:  4.216589196464891e-09\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Customer Selected: 928860\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "No delay <----- The predicted value , The probabilities :----->\n",
      "Probability of being  No delay  is:  0.6664606613533428\n",
      "Probability of being  0-3 days  is:  0.13128211862048653\n",
      "Probability of being  4-7 days  is:  0.07724526853810249\n",
      "Probability of being  8-15 days  is:  0.050000608440226954\n",
      "Probability of being  16-30 days  is:  0.07501132029926737\n",
      "Probability of being  31-60 days  is:  2.2748573990864773e-08\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Customer Selected: 928860\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "0-3 days <----- The predicted value , The probabilities :----->\n",
      "Probability of being  No delay  is:  0.1287128111153421\n",
      "Probability of being  0-3 days  is:  0.4335879955807811\n",
      "Probability of being  4-7 days  is:  0.22016602563672977\n",
      "Probability of being  8-15 days  is:  0.09579929611666883\n",
      "Probability of being  16-30 days  is:  0.12173387022020092\n",
      "Probability of being  31-60 days  is:  1.3302772399082239e-09\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(df1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import preprocessing\n",
    "    #df1=df1[df1['Status']=='Overdue']\n",
    "    #print(df1['Status'])\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df2=df1[['Net.Due.Dt','Clearing','Status']]\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['Range of Delay']=pd.to_datetime(df2['Clearing'],dayfirst=True)-pd.to_datetime(df2['Net.Due.Dt'],dayfirst=True)\n",
    "    df2['Range of Delay']=df2['Range of Delay'].dt.days\n",
    "    df2['Range of Delay']=pd.to_numeric(df2['Range of Delay'])\n",
    "    df2 = df2.reset_index()\n",
    "    df2.drop(columns = 'index',inplace=True)\n",
    "    \n",
    "    df2['Status'] = np.where(df2['Range of Delay'] > 7, 8,(np.where(df2['Range of Delay'] > 6, 7,(np.where(df2['Range of Delay'] > 5, 6,(np.where(df2['Range of Delay'] > 4, 5,(np.where(df2['Range of Delay'] > 3, 4,(np.where(df2['Range of Delay'] > 2, 3,(np.where(df2['Range of Delay'] > 1, 2,(np.where(df2['Range of Delay'] > 0, 1,0)))))))))))))))#, (np.where(df2['Range of Delay'] > 0, 1,0)))#(np.where(df2['Range of Delay'] > 0, 1,0)))))#(np.where(df2['Range of Delay'] > 0, 1,0)))))#(np.where(df2['Range of Delay'] > 10, 2,(np.where(df2['Range of Delay'] > 0,1,0)))))))# (np.where(df2['Range of Delay'] > 30, 5, (np.where(df2['Range of Delay'] > 15, 4, (np.where(df2['Range of Delay'] > 7, 3, (np.where(df2['Range of Delay'] > 3, 2, (np.where(df2['Range of Delay'] > 0, 1 ,0)))))))))))))))\n",
    "    #print(df2)\n",
    "    print('Y s in the initial set')\n",
    "    print(np.unique(df2['Status'],return_counts=True))\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    \n",
    "    df1['Status']=df2['Status']\n",
    "    df1.dropna(inplace=True)\n",
    "    y=df1['Status']\n",
    "    \n",
    "    \n",
    "    busa = preprocessing.LabelEncoder()\n",
    "    ccar= preprocessing.LabelEncoder()\n",
    "    month=preprocessing.LabelEncoder()\n",
    "    zone=preprocessing.LabelEncoder()\n",
    "    bran=preprocessing.LabelEncoder()\n",
    "    payt=preprocessing.LabelEncoder()\n",
    "    \n",
    "    df1.drop(columns='Status',inplace=True)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    arr=busa.fit(df1['BusA'])\n",
    "    df1['BusA']=busa.transform(df1['BusA'])\n",
    "    arr=ccar.fit(df1['CCAr'])\n",
    "    df1['CCAr']=ccar.transform(df1['CCAr'])#.astype('category').cat.codes\n",
    "    #df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    arr=month.fit(df1['Month'])\n",
    "    df1['Month']=month.transform(df1['Month'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Year','Clrng.doc.'],inplace=True)\n",
    "    arr=zone.fit(df1['Zone'])\n",
    "    df1['Zone']=zone.transform(df1['Zone'])    #.astype('category').cat.codes\n",
    "    arr=bran.fit(df1['Bran'])\n",
    "    df1['Bran']=bran.transform(df1['Bran'])#.astype('category').cat.codes\n",
    "    arr =payt.fit(df1['PayT'])\n",
    "    df1['PayT'] = payt.transform(df1['PayT'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1.drop(columns='Clearing',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    \n",
    "    #print('Creating Red Alert Zone')\n",
    "    #table = pd.crosstab(columns=y, index=df1['Account'])\n",
    "    #table.columns= [\"No delay\",\" 0 - 10\", \">10\"]\n",
    "    #print(table)\n",
    "    #print(table.sort_values(['>10'],ascending=False).head())\n",
    "    #arr=table.sort_values(['>10'],ascending=False)\n",
    "    #arr.drop(columns=[\"No delay\",\" 0 - 10\"],inplace=True)\n",
    "    #df_1=arr[arr['>10']>40]\n",
    "    #df_2=[]\n",
    "    \n",
    "    \n",
    "    #df1['Account']=df1['Account']/100000\n",
    "    #df1['Reference']=df1['Reference']/1000000000\n",
    "    \n",
    "\n",
    "\n",
    "    #print(df_1.index)\n",
    "    \n",
    "    \n",
    "    ###################Oversampling##############################\n",
    "    from imblearn.over_sampling import ADASYN \n",
    "    sm = ADASYN()\n",
    "    df3, y = sm.fit_resample(df1, y)\n",
    "    df1=pd.DataFrame(df3,columns=df1.columns)\n",
    "    ############################################################\n",
    "    \n",
    "    #y1=df1.columns\n",
    "    #x = df1.values #returns a numpy array\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_scaled = min_max_scaler.fit_transform(x)\n",
    "    #df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    \n",
    "    print('Y s in the set')\n",
    "    print(np.unique(y,return_counts=True))\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    \n",
    "    return df1,y,busa,ccar,month,zone,bran,payt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(df1,y):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    #y=np.array(df1['Status'])\n",
    "    \n",
    "    \n",
    "\n",
    "    X=df1\n",
    "    #df1.head(5)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3, random_state=0)\n",
    "    # Random forest Model: \n",
    "    model= RandomForestClassifier(n_estimators = 100,random_state = 30,oob_score=True,n_jobs=-1,verbose=2,max_features=None)\n",
    "    # Decion Tree Model: \n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=100)\n",
    "    # AdaBoost Classifier Model:\n",
    "    clf = AdaBoostClassifier(base_estimator=model,n_estimators=100, random_state=0)\n",
    "    # KNN :\n",
    "    mo = neighbors.KNeighborsClassifier(n_neighbors =2)\n",
    "    # Bagging Classifier Model:  \n",
    "    bagging = BaggingClassifier(mo,max_samples=0.5, max_features=0.5)\n",
    "    #Voting Classifier\n",
    "    eclf = model#VotingClassifier(estimators=[ ('knn_bagging', bagging), ('adaboost', clf), ('RF',model)],voting='soft')\n",
    "    eclf1 = eclf.fit(xtrain, ytrain)\n",
    "    print('TRAINING DONE ......................')\n",
    "    eclf1=eclf.predict(xtrain)\n",
    "    eclf2=eclf.predict(xtest)\n",
    "    print('TRAINING RESULTS-----------------------------------------')\n",
    "    print(\"Accuracy: for Training :\",metrics.accuracy_score(ytrain, eclf1)*100)\n",
    "    print(\"Accuracy: for Testing :\",metrics.accuracy_score(ytest, eclf2)*100)\n",
    "    print()\n",
    "    print('Confusion Matrix for Random Forest')\n",
    "    print(metrics.confusion_matrix(eclf2, ytest))\n",
    "    print()\n",
    "    print('--------------------------------------------------------------------------------------------------------------------')\n",
    "    return eclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df1,clf,busa,ccar,month,zone,bran,payt):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import copy\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "   \n",
    "    df1.dropna(inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    print(df1.shape)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df=copy.deepcopy(df1)\n",
    "    print(df.shape)\n",
    "    \n",
    "    df['Prediction']=np.zeros(len(df1))\n",
    "\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=busa.transform(df1['BusA'])\n",
    "    df1['CCAr']=ccar.transform(df1['CCAr'])\n",
    "    #.astype('category').cat.codes\n",
    "    #df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    df1['Month']=month.transform(df1['Month'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Year'],inplace=True)\n",
    "    df1['Zone']=zone.transform(df1['Zone'])#.astype('category').cat.codes\n",
    "    df1['Bran']=bran.transform(df1['Bran'])#.astype('category').cat.codes\n",
    "    df1['PayT'] =payt.transform(df1['PayT'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    #df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    #df1.drop(columns=['Net.Due.Dt','Clearing'],inplace=True)\n",
    "    #df1.drop(columns='Net.Due.Dt',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    \n",
    "    #y1=df1.columns\n",
    "    #x = df1.values #returns a numpy array\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_scaled = min_max_scaler.fit_transform(x)\n",
    "    #df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    \n",
    "    #df1['Account']=df1['Account']/100000\n",
    "    #df1['Reference']=df1['Reference']/1000000000\n",
    "    \n",
    "    \n",
    "    print('Starting Prediction ....')\n",
    "    prediction=clf.predict(df1)\n",
    "    print('Generating Probabilities.....')\n",
    "    predictprob=clf.predict_proba(df1)\n",
    "    print('Finished prediction...')\n",
    "    print()\n",
    "    #df['Probability']=np.zeros(len(df))\n",
    "    print(df1.head())\n",
    "    \n",
    "\n",
    "    arr=['No Delay','Next Day','Two Days','Three Days','Four Days' ,'Five Days' ,'Six Days' ,'Seven Days' ,'More than 7']\n",
    "    #arr1=['Low delay','Low Medium Delay','High Delay']#,'High Delay']#,'30 to 180','>180']#,'8-15 days','16-30 days','31-60 days','61-90 days','90-180 days','>180 days']\n",
    "    for i in range(len(arr)):\n",
    "        df[arr[i]]=np.empty(len(df))\n",
    "    print('Computing Prediction Table............')\n",
    "    #for i in range(len(prediction)):\n",
    "        #flag=0\n",
    "        #if ( i % 500 == 0):\n",
    "         #   print('----------------------------------------------------------------------------------------------------------- i =',i)\n",
    "        #for k in range(len(redzone)):\n",
    "           # if df['Account'][i] == redzone[k] :\n",
    "             #   df['Prediction'][i]='>=10'\n",
    "              #  flag=1\n",
    "              #  print('----------------------------------------------------------------RED ALERT------------------------------------------ ')\n",
    "                \n",
    "        #if(flag == 0):\n",
    "    \n",
    "        #print(arr[prediction[i]])\n",
    "        #arr2=\"\"\n",
    "        #print('Actual:',df['Arr..Clearing...Net.Due.Date.'][i])\n",
    "        #print('--------------------------------------------------------')\n",
    "    df['Prediction']=prediction\n",
    "    #df['Prediction']=np.where(df['Prediction'] == 0, 'No Delay',(np.where(df['Prediction'] == 1, 'Low Delay',(np.where(df['Prediction'] == 2, 'High Delay','')))))\n",
    "    for i in range(len(arr)):\n",
    "        df[arr[i]]=np.around(predictprob[:,i],decimals=2)\n",
    "        \n",
    "    print(df.head(5))\n",
    "            \n",
    "    print()\n",
    "    print(df.head())\n",
    "    print('Writing to csv file')\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    df.to_csv('Predictedout5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Finished Reading...\n",
      "\n",
      "     BusA CCAr     Reference   Account          Customer.Name   Zone  Bran  \\\n",
      "0  9600.0  BPR  1.115502e+09  928860.0  TATA STEEL PROCESSING  North  GBAD   \n",
      "1  9600.0  BPR  1.115502e+09  928860.0  TATA STEEL PROCESSING  North  GBAD   \n",
      "2  2500.0  BPR  2.410320e+09  928860.0  TATA STEEL PROCESSING  North  GBAD   \n",
      "3  1000.0  BPR  2.412144e+09  928860.0  TATA STEEL PROCESSING  North  GBAD   \n",
      "4  1000.0  BPR  2.412161e+09  928860.0  TATA STEEL PROCESSING  North  GBAD   \n",
      "\n",
      "   Ty   Status  Local.Crcy.Amt  ...  Doc.Chq.dt Month Pstng.Date  Net.Due.Dt  \\\n",
      "0  RV  Overdue            0.04  ...  31.10.2018   Oct   31-10-18    10-11-18   \n",
      "1  RV   Not OD            0.12  ...  05.11.2018   Nov   05-11-18    15-11-18   \n",
      "2  RV  Overdue            0.16  ...  03.11.2018   Nov   03-11-18    13-11-18   \n",
      "3  RV  Overdue            0.14  ...  31.10.2018   Oct   31-10-18    10-11-18   \n",
      "4  RV   Not OD            0.14  ...  16.12.2018   Dec   16-12-18    26-12-18   \n",
      "\n",
      "         G.L    Year  Clrng.doc.  Clearing  Pending_Amy  pending_cnt  \n",
      "0  1221001.0  2019.0  93892774.0  15-11-18         0.60          4.0  \n",
      "1  1221001.0  2019.0  93892774.0  15-11-18         1.42         10.0  \n",
      "2  1221001.0  2019.0  93892774.0  15-11-18         1.26          9.0  \n",
      "3  1221001.0  2019.0  93892774.0  15-11-18         0.60          4.0  \n",
      "4  1221001.0  2019.0  94154498.0  26-12-18         0.00          0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Preprocessing started .......\n",
      "Y s in the initial set\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([88585,  7275,  4326,  2475,  1590,  1339,  1007,   701,  2812],\n",
      "      dtype=int64))\n",
      "----------------------------------------------------------------------------------------\n",
      "Y s in the set\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), array([86143, 86396, 87034, 85932, 85966, 86232, 86190, 86102, 86255],\n",
      "      dtype=int64))\n",
      "----------------------------------------------------------------------------------------\n",
      "   BusA  CCAr   Account  Zone  Bran  Local.Crcy.Amt  PayT  Month  Pstng.Date  \\\n",
      "0   6.0   0.0  928860.0   1.0   9.0            0.04  28.0    7.0  20181031.0   \n",
      "1   6.0   0.0  928860.0   1.0   9.0            0.12  28.0    6.0  20181105.0   \n",
      "2   2.0   0.0  928860.0   1.0   9.0            0.16  28.0    6.0  20181103.0   \n",
      "3   0.0   0.0  928860.0   1.0   9.0            0.14  28.0    7.0  20181031.0   \n",
      "4   0.0   0.0  928860.0   1.0   9.0            0.14  28.0    2.0  20181216.0   \n",
      "\n",
      "   Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0  20181110.0         0.60          4.0  \n",
      "1  20181115.0         1.42         10.0  \n",
      "2  20181113.0         1.26          9.0  \n",
      "3  20181110.0         0.60          4.0  \n",
      "4  20181226.0         0.00          0.0  \n",
      "Preprocessing Done...........\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "trainpath='My Data_Delay.csv'\n",
    "\n",
    "print('Reading data...')\n",
    "df1=pd.read_csv(trainpath)\n",
    "print('Finished Reading...')\n",
    "print()\n",
    "print(df1.head(5))\n",
    "print()\n",
    "\n",
    "df3=copy.deepcopy(df1)\n",
    "print('Preprocessing started .......')\n",
    "df2,y,busa,ccar,month,zone,bran,payt=preprocessor(df1)\n",
    "print(df2.head(5))\n",
    "print('Preprocessing Done...........')\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "#print('RED ZONE VISUALISATION....')\n",
    "\n",
    "#visualisation_red(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starting............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DONE ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   30.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING RESULTS-----------------------------------------\n",
      "Accuracy: for Training : 97.74741200828157\n",
      "Accuracy: for Testing : 91.10338164251208\n",
      "\n",
      "Confusion Matrix for Random Forest\n",
      "[[23985   278   233   101    61    56    28    12   132]\n",
      " [  606 23235  1351   293   114    49    34     4   146]\n",
      " [  377  1340 22107   987   293   129    55    24   268]\n",
      " [  247   353  1128 22323   732   232    99    88   602]\n",
      " [  175   389   347   939 23211   464   210    94  1257]\n",
      " [  168   156   229   315   505 24593   259   176   263]\n",
      " [   53    78   116   136   223   161 24854   206   105]\n",
      " [   48    21    67   186   169   144   220 25034   230]\n",
      " [  235   240   351   400   473   217    88   153 22815]]\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Training Done...................\n",
      "Time Taken 749.594874382019\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "print('Training Starting............')\n",
    "clf=trainer(df2,y)\n",
    "print('Training Done...................')\n",
    "print('Time Taken',time.time()-t1)\n",
    "print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "('BusA', 0.05245150971397869)\n",
      "('CCAr', 0.0)\n",
      "('Account', 0.15977221661408036)\n",
      "('Zone', 0.021878850693367348)\n",
      "('Bran', 0.03645488039369853)\n",
      "('Local.Crcy.Amt', 0.18799999581118154)\n",
      "('PayT', 0.061102949204081186)\n",
      "('Month', 0.06826477657986513)\n",
      "('Pstng.Date', 0.10514072765648562)\n",
      "('Net.Due.Dt', 0.1350622969654681)\n",
      "('Pending_Amy', 0.08411684202903764)\n",
      "('pending_cnt', 0.08775495433875584)\n"
     ]
    }
   ],
   "source": [
    "print('Feature Importances')\n",
    "for feature in zip(df2.columns, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3099, 21)\n",
      "(3099, 21)\n",
      "Starting Prediction ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Probabilities.....\n",
      "Finished prediction...\n",
      "\n",
      "   BusA  CCAr  Account  Zone  Bran  Local.Crcy.Amt  PayT  Month  Pstng.Date  \\\n",
      "0     0     0   929488     2    21            0.10    24      2    20181231   \n",
      "1     0     0   928860     1     9            0.17    28      2    20181230   \n",
      "2     0     0   928860     1     9            0.14    28      2    20181230   \n",
      "3     0     0   928860     1     9            0.12    28      2    20181230   \n",
      "4     2     0   928860     1     9            0.14    28      2    20181231   \n",
      "\n",
      "   Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0    20190105         0.00            0  \n",
      "1    20190109         0.00            0  \n",
      "2    20190109         0.00            0  \n",
      "3    20190109         0.00            0  \n",
      "4    20190110         0.43            3  \n",
      "Computing Prediction Table............\n",
      "   BusA CCAr   Reference  Account          Customer.Name   Zone  Bran  Ty  \\\n",
      "0  1000  BPR  4132000216   929488      KAUSALYA AGENCIES  South  SBAD  RV   \n",
      "1  1000  BPR  2412166200   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "2  1000  BPR  2412166206   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "3  1000  BPR  2412166209   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "4  2500  BPR  2410325302   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "\n",
      "   Local.Crcy.Amt  Arr..Clearing...Net.Due.Date.  ... Prediction No Delay  \\\n",
      "0            0.10                             -5  ...        1.0     0.34   \n",
      "1            0.17                              5  ...        0.0     0.47   \n",
      "2            0.14                              5  ...        0.0     0.80   \n",
      "3            0.12                              5  ...        0.0     0.70   \n",
      "4            0.14                              4  ...        5.0     0.29   \n",
      "\n",
      "   Next Day Two Days Three Days Four Days Five Days  Six Days  Seven Days  \\\n",
      "0      0.62     0.02       0.00       0.0      0.02       0.0         0.0   \n",
      "1      0.16     0.00       0.17       0.0      0.20       0.0         0.0   \n",
      "2      0.18     0.00       0.00       0.0      0.02       0.0         0.0   \n",
      "3      0.30     0.00       0.00       0.0      0.00       0.0         0.0   \n",
      "4      0.04     0.24       0.00       0.0      0.43       0.0         0.0   \n",
      "\n",
      "   More than 7  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "   BusA CCAr   Reference  Account          Customer.Name   Zone  Bran  Ty  \\\n",
      "0  1000  BPR  4132000216   929488      KAUSALYA AGENCIES  South  SBAD  RV   \n",
      "1  1000  BPR  2412166200   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "2  1000  BPR  2412166206   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "3  1000  BPR  2412166209   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "4  2500  BPR  2410325302   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "\n",
      "   Local.Crcy.Amt  Arr..Clearing...Net.Due.Date.  ... Prediction No Delay  \\\n",
      "0            0.10                             -5  ...        1.0     0.34   \n",
      "1            0.17                              5  ...        0.0     0.47   \n",
      "2            0.14                              5  ...        0.0     0.80   \n",
      "3            0.12                              5  ...        0.0     0.70   \n",
      "4            0.14                              4  ...        5.0     0.29   \n",
      "\n",
      "   Next Day Two Days Three Days Four Days Five Days  Six Days  Seven Days  \\\n",
      "0      0.62     0.02       0.00       0.0      0.02       0.0         0.0   \n",
      "1      0.16     0.00       0.17       0.0      0.20       0.0         0.0   \n",
      "2      0.18     0.00       0.00       0.0      0.02       0.0         0.0   \n",
      "3      0.30     0.00       0.00       0.0      0.00       0.0         0.0   \n",
      "4      0.04     0.24       0.00       0.0      0.43       0.0         0.0   \n",
      "\n",
      "   More than 7  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Writing to csv file\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "______________________________________  END  ____________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testpath='Test.csv'\n",
    "test=pd.read_csv(testpath)\n",
    "predict(test,clf,busa,ccar,month,zone,bran,payt)\n",
    "print() \n",
    "print('______________________________________  END  ____________________________________')\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Z002', 'Z003', 'Z005', 'Z007', 'ZZ09', 'ZZ13', 'ZZ16', 'ZZ17',\n",
       "        'ZZ18', 'ZZ19', 'ZZ20', 'ZZ21', 'ZZ28', 'ZZ29', 'ZZ30', 'ZZ32',\n",
       "        'ZZ33', 'ZZ34', 'ZZ36', 'ZZ38', 'ZZ39', 'ZZ40', 'ZZ41', 'ZZ42',\n",
       "        'ZZ81', 'ZZ82'], dtype=object),\n",
       " array([146,  58,   1,  97, 114,  49,  64,  13,  66, 473, 216,  36, 616,\n",
       "         56, 143,  65,  11,  83,  21, 110,  15, 169, 380,  65,  17,  16],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test['PayT'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3028], dtype=int64),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(test['PayT']=='Z005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

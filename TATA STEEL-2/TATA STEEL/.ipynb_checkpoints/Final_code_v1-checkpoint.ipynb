{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(df1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import preprocessing\n",
    "    df2=df1[['Net.Due.Dt','Clearing','Status']]\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['Range of Delay']=pd.to_datetime(df2['Clearing'],yearfirst=True)-pd.to_datetime(df2['Net.Due.Dt'],yearfirst=True)\n",
    "    df2['Range of Delay']=df2['Range of Delay'].dt.days\n",
    "    df2['Range of Delay']=pd.to_numeric(df2['Range of Delay'])\n",
    "    df2 = df2.reset_index()\n",
    "    df2.drop(columns='index',inplace=True)\n",
    "    df2['Status'] = np.where(df2['Range of Delay'] > 180, 8, \n",
    "         (np.where(df2['Range of Delay'] > 90, 7,(np.where(df2['Range of Delay'] > 60, 6, (np.where(df2['Range of Delay'] > 30, 5, (np.where(df2['Range of Delay'] > 15, 4, (np.where(df2['Range of Delay'] > 7, 3, (np.where(df2['Range of Delay'] > 3, 2, (np.where(df2['Range of Delay'] > 0, 1 ,0)))))))))))))))\n",
    "    print(df2.head())\n",
    "    df1['Status']=df2['Status']\n",
    "    df1.dropna(inplace=True)\n",
    "    df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=df1['BusA'].astype('category').cat.codes\n",
    "    df1['CCAr']=df1['CCAr'].astype('category').cat.codes\n",
    "    df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    df1['Month']=df1['Month'].astype('category').cat.codes\n",
    "    #df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Year','Clrng.doc.'],inplace=True)\n",
    "    df1['Zone']=df1['Zone'].astype('category').cat.codes\n",
    "    df1['Bran']=df1['Bran'].astype('category').cat.codes\n",
    "    df1['PayT'] = df1['PayT'].astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1.drop(columns='Clearing',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    y=df1['Status']\n",
    "    df1.drop(columns='Status',inplace=True)\n",
    "    print('Y s in the set')\n",
    "    print(np.unique(y,return_counts=True))\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    y1=df1.columns\n",
    "    x = df1.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    return df1,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(df1,y):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    #y=np.array(df1['Status'])\n",
    "    \n",
    "    \n",
    "\n",
    "    X=df1\n",
    "    #df1.head(5)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3, random_state=0)\n",
    "    # Random forest Model: \n",
    "    model= RandomForestClassifier(n_estimators = 300, criterion='entropy',random_state = 0)\n",
    "    # Decion Tree Model: \n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=100)\n",
    "    # AdaBoost Classifier Model:\n",
    "    clf = AdaBoostClassifier(base_estimator=decision_tree,n_estimators=100, random_state=0)\n",
    "    # KNN :\n",
    "    mo = neighbors.KNeighborsClassifier(n_neighbors =2)\n",
    "    # Bagging Classifier Model:  \n",
    "    bagging = BaggingClassifier(mo,max_samples=0.5, max_features=0.5)\n",
    "    #Voting Classifier\n",
    "    eclf = VotingClassifier(estimators=[ ('knn_bagging', bagging), ('adaboost', clf), ('RF',model)],voting='soft')\n",
    "    eclf1 = eclf.fit(xtrain, ytrain)\n",
    "    eclf2=eclf.predict(xtest)\n",
    "    print('TRAINING RESULTS-----------------------------------------')\n",
    "    print(\"Accuracy: for Voting :\",metrics.accuracy_score(ytest, eclf2)*100)\n",
    "    print()\n",
    "    print('Confusion Matrix for Voting')\n",
    "    print(metrics.confusion_matrix(eclf2, ytest))\n",
    "    print()\n",
    "    print('--------------------------------------------------------------------------------------------------------------------')\n",
    "    return eclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df1,clf):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import copy\n",
    "    from sklearn import preprocessing\n",
    "    df=copy.deepcopy(df1)\n",
    "    print(df.shape)\n",
    "    df['Prediction']=np.zeros(len(df1))\n",
    "    df['Pro']=np.zeros(len(df1))\n",
    "    print(df1.shape)\n",
    "    df1.dropna(inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=df1['BusA'].astype('category').cat.codes\n",
    "    df1['CCAr']=df1['CCAr'].astype('category').cat.codes\n",
    "    df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    #df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1['Month']=df1['Month'].astype('category').cat.codes\n",
    "    df1.drop(columns=['DocumentNo','Year'],inplace=True)\n",
    "    df1['Zone']=df1['Zone'].astype('category').cat.codes\n",
    "    df1['Bran']=df1['Bran'].astype('category').cat.codes\n",
    "    df1['PayT'] = df1['PayT'].astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    #df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    #df1.drop(columns=['Net.Due.Dt','Clearing'],inplace=True)\n",
    "    #df1.drop(columns='Net.Due.Dt',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    y1=df1.columns\n",
    "    x = df1.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    prediction=clf.predict(df1)\n",
    "    predictprob=clf.predict_proba(df1)\n",
    "    #df['Probability']=np.zeros(len(df))\n",
    "    print(df1.head())\n",
    "    \n",
    "    arr=['No delay','0-3 days','4-7 days','8-15 days','16-30 days','31-60 days','61-90 days','90-180 days','>180 days']\n",
    "    for i in range(len(prediction)):\n",
    "        df['Prediction'][i]=arr[prediction[i]]\n",
    "        arr2=\"\"\n",
    "        for j in range(len(predictprob[i])):\n",
    "            arr2=arr2+'  Probability of being in ('+str(arr[j])+' delay) is: '+str(predictprob[i][j])+'  , '\n",
    "        df['Pro'][i]=arr2\n",
    "            \n",
    "    print()\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    df.to_csv('Predictedout.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import time\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import copy\n",
    "    trainpath='MyData.csv'\n",
    "    testpath='Test.csv'\n",
    "    print('Reading data...')\n",
    "    df1=pd.read_csv(trainpath)\n",
    "    print('Finished Reading...')\n",
    "    print()\n",
    "    print(df1.head(5))\n",
    "    print()\n",
    "    #df3=copy.deepcopy(df1)\n",
    "    print('Preprocessing started .......')\n",
    "    df2,y=preprocessor(df1)\n",
    "    print(df2.head(5))\n",
    "    print('Preprocessing Done...........')\n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    t1=time.time()\n",
    "    print('Training Starting............')\n",
    "    clf=trainer(df2,y)\n",
    "    print('Training Done...................')\n",
    "    print('Time Taken',time.time()-t1)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    test=pd.read_csv(testpath)\n",
    "    predict(test,clf)\n",
    "    print()\n",
    "    print('______________________________________ END ____________________________________')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Finished Reading...\n",
      "\n",
      "   BusA CCAr     Reference  Account          Customer.Name   Zone  Bran  Ty  \\\n",
      "0  1000  BPR  4.132000e+09   929488      KAUSALYA AGENCIES  South  SBAD  RV   \n",
      "1  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "2  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "3  9600  BPR  2.146119e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "4  2500  BPR  2.410320e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "\n",
      "    Status  Local.Crcy.Amt  ...  Doc.Chq.dt Month  Pstng.Date  Net.Due.Dt  \\\n",
      "0   Not OD            0.10  ...  31.12.2018   Dec  2018-12-31  2019-01-05   \n",
      "1  Overdue            0.04  ...  31.10.2018   Oct  2018-10-31  2018-11-10   \n",
      "2   Not OD            0.12  ...  05.11.2018   Nov  2018-11-05  2018-11-15   \n",
      "3  Overdue            0.14  ...  27.10.2018   Oct  2018-10-27  2018-11-06   \n",
      "4  Overdue            0.16  ...  03.11.2018   Nov  2018-11-03  2018-11-13   \n",
      "\n",
      "       G.L  Year Clrng.doc.    Clearing  Pending_Amy  pending_cnt  \n",
      "0  1221001  2019   94177601  2018-12-31         0.00            0  \n",
      "1  1221001  2019   93892774  2018-11-15         0.60            4  \n",
      "2  1221001  2019   93892774  2018-11-15         1.42           10  \n",
      "3  1221001  2019   93892773  2018-11-14         0.00            0  \n",
      "4  1221001  2019   93892774  2018-11-15         1.26            9  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Preprocessing started .......\n",
      "   Net.Due.Dt    Clearing  Status  Range of Delay\n",
      "0  2019-01-05  2018-12-31       0              -5\n",
      "1  2018-11-10  2018-11-15       2               5\n",
      "2  2018-11-15  2018-11-15       0               0\n",
      "3  2018-11-06  2018-11-14       3               8\n",
      "4  2018-11-13  2018-11-15       1               2\n",
      "Y s in the set\n",
      "(array([0, 1, 2, 3, 4, 5], dtype=int8), array([90293, 14763,  5367,  2652,   628,     9], dtype=int64))\n",
      "----------------------------------------------------------------------------------------\n",
      "       BusA  CCAr  Reference   Account      Zone      Bran  Local.Crcy.Amt  \\\n",
      "0  0.000000   0.0   0.927817  1.000000  0.666667  0.954545        0.196078   \n",
      "1  1.000000   0.0   0.207218  0.994083  0.333333  0.409091        0.078431   \n",
      "2  1.000000   0.0   0.207218  0.994083  0.333333  0.409091        0.235294   \n",
      "3  1.000000   0.0   0.453418  0.994083  0.333333  0.409091        0.274510   \n",
      "4  0.333333   0.0   0.516532  0.994083  0.333333  0.409091        0.313725   \n",
      "\n",
      "       PayT  Month  Pstng.Date  Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0  0.750000  0.250    1.000000    0.997430     0.000000     0.000000  \n",
      "1  0.861111  0.875    0.759036    0.072875     0.020263     0.014815  \n",
      "2  0.861111  0.750    0.848193    0.073389     0.047957     0.037037  \n",
      "3  0.861111  0.875    0.754217    0.072464     0.000000     0.000000  \n",
      "4  0.861111  0.750    0.845783    0.073183     0.042553     0.033333  \n",
      "Preprocessing Done...........\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Training Starting............\n",
      "TRAINING RESULTS-----------------------------------------\n",
      "Accuracy: for Voting : 93.64190654863106\n",
      "\n",
      "Confusion Matrix for Voting\n",
      "[[26612   890   164    63    48     0]\n",
      " [  408  3452   202    29     7     0]\n",
      " [   50   107  1151    61     3     1]\n",
      " [   12    20    66   594    13     0]\n",
      " [    5     2     4    14   134     0]\n",
      " [    0     0     0     0     0     2]]\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Training Done...................\n",
      "Time Taken 168.11761593818665\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "(586, 21)\n",
      "(586, 21)\n",
      "   BusA  CCAr     Reference   Account  Zone  Bran  Local.Crcy.Amt  PayT  \\\n",
      "0  1.00   0.0  9.252208e-07  1.000000   0.0   0.5        0.416667   1.0   \n",
      "1  1.00   0.0  5.666977e-06  1.000000   0.0   0.5        0.416667   1.0   \n",
      "2  1.00   0.0  2.639252e-06  1.000000   0.0   0.5        0.361111   1.0   \n",
      "3  1.00   0.0  9.548753e-07  1.000000   0.0   0.5        0.416667   1.0   \n",
      "4  0.25   0.0  3.912320e-01  0.666667   0.0   0.5        0.277778   0.0   \n",
      "\n",
      "   Month  Pstng.Date  Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0  0.500    0.465778    0.082698     0.671521         0.66  \n",
      "1  0.375    0.445333    0.055989     1.000000         1.00  \n",
      "2  0.375    0.000889    0.091877     0.899676         0.88  \n",
      "3  0.500    0.465778    0.082698     0.671521         0.66  \n",
      "4  1.000    0.730667    0.075447     0.000000         0.00  \n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "______________________________________ END ____________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

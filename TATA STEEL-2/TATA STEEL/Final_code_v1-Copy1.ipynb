{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(df1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import preprocessing\n",
    "    #df1=df1[df1['Status']=='Overdue']\n",
    "    #print(df1['Status'])\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df2=df1[['Net.Due.Dt','Clearing','Status']]\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['Range of Delay']=pd.to_datetime(df2['Clearing'],dayfirst=True)-pd.to_datetime(df2['Net.Due.Dt'],dayfirst=True)\n",
    "    df2['Range of Delay']=df2['Range of Delay'].dt.days\n",
    "    df2['Range of Delay']=pd.to_numeric(df2['Range of Delay'])\n",
    "    df2 = df2.reset_index()\n",
    "    df2.drop(columns = 'index',inplace=True)\n",
    "    \n",
    "    df2['Status'] = np.where(df2['Range of Delay'] > 15, 2, (np.where(df2['Range of Delay'] > 0, 1,0)))#(np.where(df2['Range of Delay'] > 0, 1,0)))))#(np.where(df2['Range of Delay'] > 0, 1,0)))))#(np.where(df2['Range of Delay'] > 10, 2,(np.where(df2['Range of Delay'] > 0,1,0)))))))# (np.where(df2['Range of Delay'] > 30, 5, (np.where(df2['Range of Delay'] > 15, 4, (np.where(df2['Range of Delay'] > 7, 3, (np.where(df2['Range of Delay'] > 3, 2, (np.where(df2['Range of Delay'] > 0, 1 ,0)))))))))))))))\n",
    "    #print(df2)\n",
    "    print('Y s in the initial set')\n",
    "    print(np.unique(df2['Status'],return_counts=True))\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    \n",
    "    df1['Status']=df2['Status']\n",
    "    df1.dropna(inplace=True)\n",
    "    y=df1['Status']\n",
    "    \n",
    "    \n",
    "    busa = preprocessing.LabelEncoder()\n",
    "    ccar= preprocessing.LabelEncoder()\n",
    "    month=preprocessing.LabelEncoder()\n",
    "    zone=preprocessing.LabelEncoder()\n",
    "    bran=preprocessing.LabelEncoder()\n",
    "    payt=preprocessing.LabelEncoder()\n",
    "    \n",
    "    df1.drop(columns='Status',inplace=True)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=busa.fit_transform(df1['BusA'])\n",
    "    df1['CCAr']=ccar.fit_transform(df1['CCAr'])#.astype('category').cat.codes\n",
    "    #df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    df1['Month']=month.fit_transform(df1['Month'])#.astype('category').cat.codes\n",
    "    #df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Year','Clrng.doc.'],inplace=True)\n",
    "    df1['Zone']=zone.fit_transform(df1['Zone'])#.astype('category').cat.codes\n",
    "    df1['Bran']=bran.fit_transform(df1['Bran'])#.astype('category').cat.codes\n",
    "    df1['PayT'] =payt.fit_transform(df1['PayT'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    df1.drop(columns='Clearing',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    \n",
    "    #print('Creating Red Alert Zone')\n",
    "    #table = pd.crosstab(columns=y, index=df1['Account'])\n",
    "    #table.columns= [\"No delay\",\" 0 - 10\", \">10\"]\n",
    "    #print(table)\n",
    "    #print(table.sort_values(['>10'],ascending=False).head())\n",
    "    #arr=table.sort_values(['>10'],ascending=False)\n",
    "    #arr.drop(columns=[\"No delay\",\" 0 - 10\"],inplace=True)\n",
    "    #df_1=arr[arr['>10']>40]\n",
    "    #df_2=[]\n",
    "    \n",
    "    \n",
    "    #df1['Account']=df1['Account']/100000\n",
    "    #df1['Reference']=df1['Reference']/1000000000\n",
    "    \n",
    "\n",
    "\n",
    "    #print(df_1.index)\n",
    "    \n",
    "    \n",
    "    ###################Oversampling##############################\n",
    "    from imblearn.over_sampling import ADASYN \n",
    "    sm = ADASYN()\n",
    "    df3, y = sm.fit_resample(df1, y)\n",
    "    df1=pd.DataFrame(df3,columns=df1.columns)\n",
    "    ############################################################\n",
    "    \n",
    "    #y1=df1.columns\n",
    "    #x = df1.values #returns a numpy array\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_scaled = min_max_scaler.fit_transform(x)\n",
    "    #df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    \n",
    "    print('Y s in the set')\n",
    "    print(np.unique(y,return_counts=True))\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    \n",
    "    return df1,y,busa,ccar,month,zone,bran,payt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(df1,y):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    #y=np.array(df1['Status'])\n",
    "    \n",
    "    \n",
    "\n",
    "    X=df1\n",
    "    #df1.head(5)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3, random_state=0)\n",
    "    # Random forest Model: \n",
    "    model= RandomForestClassifier(n_estimators = 300,random_state = 30,oob_score=True,n_jobs=-1,verbose=1,max_features=None,class_weight={0:10,1:20,2:1000})\n",
    "    # Decion Tree Model: \n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=100)\n",
    "    # AdaBoost Classifier Model:\n",
    "    clf = AdaBoostClassifier(base_estimator=model,n_estimators=100, random_state=0)\n",
    "    # KNN :\n",
    "    mo = neighbors.KNeighborsClassifier(n_neighbors =2)\n",
    "    # Bagging Classifier Model:  \n",
    "    bagging = BaggingClassifier(mo,max_samples=0.5, max_features=0.5)\n",
    "    #Voting Classifier\n",
    "    eclf = model#VotingClassifier(estimators=[ ('knn_bagging', bagging), ('adaboost', clf), ('RF',model)],voting='soft')\n",
    "    eclf1 = eclf.fit(xtrain, ytrain)\n",
    "    print('TRAINING DONE ......................')\n",
    "    eclf1=eclf.predict(xtrain)\n",
    "    eclf2=eclf.predict(xtest)\n",
    "    print('TRAINING RESULTS-----------------------------------------')\n",
    "    print(\"Accuracy: for Training :\",metrics.accuracy_score(ytrain, eclf1)*100)\n",
    "    print(\"Accuracy: for Testing :\",metrics.accuracy_score(ytest, eclf2)*100)\n",
    "    print()\n",
    "    print('Confusion Matrix for Random Forest')\n",
    "    print(metrics.confusion_matrix(eclf2, ytest))\n",
    "    print()\n",
    "    print('--------------------------------------------------------------------------------------------------------------------')\n",
    "    return eclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df1,clf,busa,ccar,month,zone,bran,payt):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import copy\n",
    "    from sklearn import preprocessing\n",
    "    df=copy.deepcopy(df1)\n",
    "    print(df.shape)\n",
    "    df['Prediction']=np.zeros(len(df1))\n",
    "    print(df1.shape)\n",
    "    df1.dropna(inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes)\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    busa = preprocessing.LabelEncoder()\n",
    "    ccar= preprocessing.LabelEncoder()\n",
    "    month=preprocessing.LabelEncoder()\n",
    "    zone=preprocessing.LabelEncoder()\n",
    "    bran=preprocessing.LabelEncoder()\n",
    "    payt=preprocessing.LabelEncoder()\n",
    "    \n",
    "\n",
    "    #df1['Status']=df1['Status'].astype('category').cat.codes\n",
    "    df1['BusA']=busa.fit_transform(df1['BusA'])\n",
    "    df1['CCAr']=ccar.fit_transform(df1['CCAr'])#.astype('category').cat.codes\n",
    "    #df1['Account']=df1['Account'].astype('category').cat.codes\n",
    "    df1['Month']=month.fit_transform(df1['Month'])#.astype('category').cat.codes\n",
    "    #df1.drop(columns='Reference',inplace=True)\n",
    "    df1.drop(columns='Customer.Name',inplace=True)\n",
    "    df1.drop(columns=['DocumentNo','Year'],inplace=True)\n",
    "    df1['Zone']=zone.fit_transform(df1['Zone'])#.astype('category').cat.codes\n",
    "    df1['Bran']=bran.fit_transform(df1['Bran'])#.astype('category').cat.codes\n",
    "    df1['PayT'] =payt.fit_transform(df1['PayT'])#.astype('category').cat.codes\n",
    "    df1.drop(columns='Doc.Chq.dt',inplace=True)\n",
    "    df1.drop(columns='Ty',inplace=True)\n",
    "    df1.drop(columns='Sale.Type',inplace=True)\n",
    "    df1['Pstng.Date']=pd.to_datetime(df1['Pstng.Date'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    df1['Net.Due.Dt']=pd.to_datetime(df1['Net.Due.Dt'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    #df1['Clearing']=pd.to_datetime(df1['Clearing']).dt.strftime(\"%Y%m%d\").astype(str)\n",
    "    #df1.drop(columns=['Net.Due.Dt','Clearing'],inplace=True)\n",
    "    #df1.drop(columns='Net.Due.Dt',inplace=True)\n",
    "    df1 = df1.reset_index()\n",
    "    df1.drop(columns='index',inplace=True)\n",
    "    df1.drop(columns='Arr..Clearing...Net.Due.Date.',inplace=True)\n",
    "    df1.drop(columns='G.L',inplace=True)\n",
    "    \n",
    "    #y1=df1.columns\n",
    "    #x = df1.values #returns a numpy array\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_scaled = min_max_scaler.fit_transform(x)\n",
    "    #df1 = pd.DataFrame(x_scaled,columns=df1.columns)\n",
    "    \n",
    "    #df1['Account']=df1['Account']/100000\n",
    "    #df1['Reference']=df1['Reference']/1000000000\n",
    "    \n",
    "    \n",
    "    print('Starting Prediction ....')\n",
    "    prediction=clf.predict(df1)\n",
    "    print('Generating Probabilities.....')\n",
    "    predictprob=clf.predict_proba(df1)\n",
    "    print('Finished prediction...')\n",
    "    print()\n",
    "    #df['Probability']=np.zeros(len(df))\n",
    "    print(df1.head())\n",
    "    \n",
    "\n",
    "    arr=['No Delay','Low Delay','High Delay']\n",
    "    arr1=['Low delay','Low Medium Delay','High Delay']#,'High Delay']#,'30 to 180','>180']#,'8-15 days','16-30 days','31-60 days','61-90 days','90-180 days','>180 days']\n",
    "    for i in range(len(arr)):\n",
    "        df[arr1[i]]=np.empty(len(df))\n",
    "    print('Computing Prediction Table............')\n",
    "    #for i in range(len(prediction)):\n",
    "        #flag=0\n",
    "        #if ( i % 500 == 0):\n",
    "         #   print('----------------------------------------------------------------------------------------------------------- i =',i)\n",
    "        #for k in range(len(redzone)):\n",
    "           # if df['Account'][i] == redzone[k] :\n",
    "             #   df['Prediction'][i]='>=10'\n",
    "              #  flag=1\n",
    "              #  print('----------------------------------------------------------------RED ALERT------------------------------------------ ')\n",
    "                \n",
    "        #if(flag == 0):\n",
    "    \n",
    "        #print(arr[prediction[i]])\n",
    "        #arr2=\"\"\n",
    "        #print('Actual:',df['Arr..Clearing...Net.Due.Date.'][i])\n",
    "        #print('--------------------------------------------------------')\n",
    "    df['Prediction']=prediction\n",
    "    df['Prediction']=np.where(df['Prediction'] == 0, 'No Delay',(np.where(df['Prediction'] == 1, 'Low Delay',(np.where(df['Prediction'] == 2, 'High Delay','')))))\n",
    "    for i in range(len(arr1)):\n",
    "        df[arr1[i]]=np.around(predictprob[:,i],decimals=2)\n",
    "        \n",
    "    print(df.head(5))\n",
    "            \n",
    "    print()\n",
    "    print(df.head())\n",
    "    print('Writing to csv file')\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    df.to_csv('Predictedout5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Finished Reading...\n",
      "\n",
      "   BusA CCAr     Reference  Account          Customer.Name   Zone  Bran  Ty  \\\n",
      "0  1000  BPR  4.132000e+09   929488      KAUSALYA AGENCIES  South  SBAD  RV   \n",
      "1  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "2  9600  BPR  1.115502e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "3  1000  BPR  2.412166e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "4  2500  BPR  2.410320e+09   928860  TATA STEEL PROCESSING  North  GBAD  RV   \n",
      "\n",
      "    Status  Local.Crcy.Amt  ...  Doc.Chq.dt Month Pstng.Date  Net.Due.Dt  \\\n",
      "0   Not OD            0.10  ...  31.12.2018   Dec   31-12-18    05-01-19   \n",
      "1  Overdue            0.04  ...  31.10.2018   Oct   31-10-18    10-11-18   \n",
      "2   Not OD            0.12  ...  05.11.2018   Nov   05-11-18    15-11-18   \n",
      "3  Overdue            0.17  ...  30.12.2018   Dec   30-12-18    09-01-19   \n",
      "4  Overdue            0.16  ...  03.11.2018   Nov   03-11-18    13-11-18   \n",
      "\n",
      "       G.L  Year Clrng.doc.  Clearing  Pending_Amy  pending_cnt  \n",
      "0  1221001  2019   94177601  31-12-18         0.00            0  \n",
      "1  1221001  2019   93892774  15-11-18         0.60            4  \n",
      "2  1221001  2019   93892774  15-11-18         1.42           10  \n",
      "3  1221001  2019   94398427  14-01-19         0.00            0  \n",
      "4  1221001  2019   93892774  15-11-18         1.26            9  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Preprocessing started .......\n",
      "Y s in the initial set\n",
      "(array([0, 1, 2]), array([90293, 22782,   637], dtype=int64))\n",
      "----------------------------------------------------------------------------------------\n",
      "Y s in the set\n",
      "(array([0, 1, 2]), array([90293, 88767, 90314], dtype=int64))\n",
      "----------------------------------------------------------------------------------------\n",
      "   BusA  CCAr     Reference   Account  Zone  Bran  Local.Crcy.Amt  PayT  \\\n",
      "0   0.0   0.0  4.132000e+09  929488.0   2.0  21.0            0.10  27.0   \n",
      "1   6.0   0.0  1.115502e+09  928860.0   1.0   9.0            0.04  31.0   \n",
      "2   6.0   0.0  1.115502e+09  928860.0   1.0   9.0            0.12  31.0   \n",
      "3   0.0   0.0  2.412166e+09  928860.0   1.0   9.0            0.17  31.0   \n",
      "4   2.0   0.0  2.410320e+09  928860.0   1.0   9.0            0.16  31.0   \n",
      "\n",
      "   Month  Pstng.Date  Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0    2.0  20181231.0  20190105.0         0.00          0.0  \n",
      "1    7.0  20181031.0  20181110.0         0.60          4.0  \n",
      "2    6.0  20181105.0  20181115.0         1.42         10.0  \n",
      "3    2.0  20181230.0  20190109.0         0.00          0.0  \n",
      "4    6.0  20181103.0  20181113.0         1.26          9.0  \n",
      "Preprocessing Done...........\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "trainpath='MyData.csv'\n",
    "\n",
    "print('Reading data...')\n",
    "df1=pd.read_csv(trainpath)\n",
    "print('Finished Reading...')\n",
    "print()\n",
    "print(df1.head(5))\n",
    "print()\n",
    "\n",
    "df3=copy.deepcopy(df1)\n",
    "print('Preprocessing started .......')\n",
    "df2,y,busa,ccar,month,zone,bran,payt=preprocessor(df1)\n",
    "print(df2.head(5))\n",
    "print('Preprocessing Done...........')\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "#print('RED ZONE VISUALISATION....')\n",
    "\n",
    "#visualisation_red(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starting............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DONE ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=2)]: Done 300 out of 300 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=2)]: Done 300 out of 300 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING RESULTS-----------------------------------------\n",
      "Accuracy: for Training : 99.65157163994675\n",
      "Accuracy: for Testing : 97.36057317510797\n",
      "\n",
      "Confusion Matrix for Random Forest\n",
      "[[25898   698    35]\n",
      " [ 1187 25775    40]\n",
      " [   38   135 27007]]\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Training Done...................\n",
      "Time Taken 1187.8959438800812\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "print('Training Starting............')\n",
    "clf=trainer(df2,y)\n",
    "print('Training Done...................')\n",
    "print('Time Taken',time.time()-t1)\n",
    "print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "('BusA', 0.04039194374611351)\n",
      "('CCAr', 0.0)\n",
      "('Reference', 0.14683947545504744)\n",
      "('Account', 0.13148644030481524)\n",
      "('Zone', 0.07628144365015575)\n",
      "('Bran', 0.11761115048602398)\n",
      "('Local.Crcy.Amt', 0.06711158629359033)\n",
      "('PayT', 0.04828126390305931)\n",
      "('Month', 0.10575127149788208)\n",
      "('Pstng.Date', 0.034889041429202565)\n",
      "('Net.Due.Dt', 0.12680460634917434)\n",
      "('Pending_Amy', 0.054022944173949636)\n",
      "('pending_cnt', 0.05052883271098587)\n"
     ]
    }
   ],
   "source": [
    "print('Feature Importances')\n",
    "for feature in zip(df2.columns, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5273, 21)\n",
      "(5273, 21)\n",
      "Starting Prediction ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 300 out of 300 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Probabilities.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 300 out of 300 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prediction...\n",
      "\n",
      "   BusA  CCAr     Reference  Account  Zone  Bran  Local.Crcy.Amt  PayT  Month  \\\n",
      "0     1     0  2.412118e+09   926346     1     8            0.14     8      0   \n",
      "1     1     0  2.412118e+09   926346     1     8            0.15     8      0   \n",
      "2     1     0  2.412118e+09   926346     1     8            0.15     8      0   \n",
      "3     1     0  2.412118e+09   926346     1     8            0.16     8      0   \n",
      "4     1     0  2.412118e+09   926346     1     8            0.16     8      0   \n",
      "\n",
      "   Pstng.Date  Net.Due.Dt  Pending_Amy  pending_cnt  \n",
      "0    20180901    20180911         1.49           11  \n",
      "1    20180901    20180911         1.49           11  \n",
      "2    20180901    20180911         1.49           11  \n",
      "3    20180901    20180911         1.49           11  \n",
      "4    20180901    20180911         1.49           11  \n",
      "Computing Prediction Table............\n",
      "   BusA CCAr     Reference  Account         Customer.Name   Zone  Bran  Ty  \\\n",
      "0  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "1  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "2  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "3  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "4  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "\n",
      "   Local.Crcy.Amt  Arr..Clearing...Net.Due.Date.  ... Pstng.Date Net.Due.Dt  \\\n",
      "0            0.14                              3  ...   01-09-18   11-09-18   \n",
      "1            0.15                              3  ...   01-09-18   11-09-18   \n",
      "2            0.15                              3  ...   01-09-18   11-09-18   \n",
      "3            0.16                              3  ...   01-09-18   11-09-18   \n",
      "4            0.16                              3  ...   01-09-18   11-09-18   \n",
      "\n",
      "       G.L  Year Pending_Amy pending_cnt Prediction  Low delay  \\\n",
      "0  1221001  2019        1.49          11   No Delay       0.92   \n",
      "1  1221001  2019        1.49          11   No Delay       0.91   \n",
      "2  1221001  2019        1.49          11   No Delay       0.91   \n",
      "3  1221001  2019        1.49          11   No Delay       0.91   \n",
      "4  1221001  2019        1.49          11   No Delay       0.91   \n",
      "\n",
      "   Low Medium Delay  High Delay  \n",
      "0              0.08         0.0  \n",
      "1              0.09         0.0  \n",
      "2              0.09         0.0  \n",
      "3              0.09         0.0  \n",
      "4              0.09         0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "   BusA CCAr     Reference  Account         Customer.Name   Zone  Bran  Ty  \\\n",
      "0  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "1  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "2  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "3  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "4  2000  BPR  2.412118e+09   926346  GRG STEELS PVT. LTD.  North  FBAD  RV   \n",
      "\n",
      "   Local.Crcy.Amt  Arr..Clearing...Net.Due.Date.  ... Pstng.Date Net.Due.Dt  \\\n",
      "0            0.14                              3  ...   01-09-18   11-09-18   \n",
      "1            0.15                              3  ...   01-09-18   11-09-18   \n",
      "2            0.15                              3  ...   01-09-18   11-09-18   \n",
      "3            0.16                              3  ...   01-09-18   11-09-18   \n",
      "4            0.16                              3  ...   01-09-18   11-09-18   \n",
      "\n",
      "       G.L  Year Pending_Amy pending_cnt Prediction  Low delay  \\\n",
      "0  1221001  2019        1.49          11   No Delay       0.92   \n",
      "1  1221001  2019        1.49          11   No Delay       0.91   \n",
      "2  1221001  2019        1.49          11   No Delay       0.91   \n",
      "3  1221001  2019        1.49          11   No Delay       0.91   \n",
      "4  1221001  2019        1.49          11   No Delay       0.91   \n",
      "\n",
      "   Low Medium Delay  High Delay  \n",
      "0              0.08         0.0  \n",
      "1              0.09         0.0  \n",
      "2              0.09         0.0  \n",
      "3              0.09         0.0  \n",
      "4              0.09         0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Writing to csv file\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "______________________________________  END  ____________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testpath='Test.csv'\n",
    "test=pd.read_csv(testpath)\n",
    "predict(test,clf,busa,ccar,month,zone,bran,payt)\n",
    "print() \n",
    "print('______________________________________  END  ____________________________________')\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
